{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'positive_words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f1b6c971f5aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# lists of words to use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpositive_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positive_words.txt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpos_f\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlin\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos_f\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m';'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'positive_words.txt'"
     ]
    }
   ],
   "source": [
    "def strip_punctuation(str1):\n",
    "    punctuation_chars = [\"'\", '\"', \",\", \".\", \"!\", \":\", \";\", '#', '@']\n",
    "    for i in punctuation_chars:\n",
    "        str1 = str1.replace(i,\"\")\n",
    "    print (str1)\n",
    "    return str1\n",
    "\n",
    "# lists of words to use\n",
    "positive_words = []\n",
    "with open(\"positive_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            positive_words.append(lin.strip())\n",
    "\n",
    "\n",
    "negative_words = []\n",
    "with open(\"negative_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            negative_words.append(lin.strip())\n",
    "\n",
    "def get_pos(str1):\n",
    "    global positive_words\n",
    "    poscount = 0\n",
    "    str1 = strip_punctuation(str1) #strip stuff\n",
    "    str1 = str1.lower() #to lowercase\n",
    "    arr1 = str1.split() #split to list\n",
    "    for i in arr1:\n",
    "        if i in positive_words:\n",
    "            poscount +=1\n",
    "    print (poscount)\n",
    "    return poscount\n",
    "\n",
    "def get_neg(str1):\n",
    "    global negative_words\n",
    "    count = 0\n",
    "    str1 = strip_punctuation(str1) #strip stuff\n",
    "    str1 = str1.lower() #to lowercase\n",
    "    arr1 = str1.split() #split to list\n",
    "    for i in arr1:\n",
    "        if i in negative_words:\n",
    "            count +=1\n",
    "    print (count)\n",
    "    return count\n",
    "\n",
    "#create new file\n",
    "outfile = open(\"resulting_data.csv\", \"w\")\n",
    "# output the header row\n",
    "outfile.write('Number of Retweets, Number of Replies, Positive Score, Negative Score, Net Score')\n",
    "outfile.write('\\n')\n",
    "\n",
    "#import csv\n",
    "fileconnection = open(\"project_twitter_data.csv\", 'r')\n",
    "lines = fileconnection.readlines()\n",
    "header = lines[0]\n",
    "field_names = header.strip().split(',')\n",
    "print(field_names)\n",
    "for row in lines[1:]:\n",
    "    vals = row.strip().split(',')\n",
    "    print(\":{}:: {}::: {}\".format(vals[0],vals[1],vals[2]))\n",
    "    print(\"---\")\n",
    "    \n",
    "    posscore = get_pos(vals[0])\n",
    "    negscore = get_neg(vals[0])\n",
    "    netscore = posscore-negscore\n",
    "    #write to new csv file\n",
    "    row_string = '{},{},{},{},{}\\n'.format(vals[1],vals[2],posscore,negscore,netscore)\n",
    "    print(\"--\",row_string)\n",
    "    outfile.write(row_string)\n",
    "    \n",
    "    \n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tastedive.com/api/similar?q=Sherlock+Holmes&type=movies&limit=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Similar': {'Info': [{'Name': 'Sherlock Holmes', 'Type': 'movie'}],\n",
       "  'Results': [{'Name': 'The Lord Of The Rings', 'Type': 'movie'},\n",
       "   {'Name': 'Underworld', 'Type': 'movie'},\n",
       "   {'Name': 'Captain America', 'Type': 'movie'},\n",
       "   {'Name': 'Sweeney Todd', 'Type': 'movie'},\n",
       "   {'Name': \"A Hitman's Solitude Before The Shot\", 'Type': 'movie'}]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# some invocations that we use in the automated tests; uncomment these if you are getting errors and want better error messages\n",
    "# get_movies_from_tastedive(\"Bridesmaids\")\n",
    "# get_movies_from_tastedive(\"Black Panther\")\n",
    "\n",
    "def get_movies_from_tastedive(title1):\n",
    "    kval_pairs = {'q':title1, 'type':'movies', 'limit':'5'}\n",
    "    page = requests.get(\"https://tastedive.com/api/similar\", params=kval_pairs)  \n",
    "    #str1 = page.text[:400] # print the first 400 characters\n",
    "    obj1 = page.json()\n",
    "    print(page.url) # print the url that was fetched\n",
    "    return obj1\n",
    "    \n",
    "get_movies_from_tastedive(\"Sherlock Holmes\")\n",
    "#get_movies_from_tastedive(\"Black Panther\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# some invocations that we use in the automated tests; uncomment these if you are getting errors and want better error messages\n",
    "# extract_movie_titles(get_movies_from_tastedive(\"Tony Bennett\"))\n",
    "# extract_movie_titles(get_movies_from_tastedive(\"Black Panther\"))\n",
    "import requests_with_caching\n",
    "\n",
    "def get_movies_from_tastedive(title1):\n",
    "    kval_pairs = {'q':title1, 'type':'movies', 'limit':'5'}\n",
    "    page = requests_with_caching.get(\"https://tastedive.com/api/similar\", params=kval_pairs)  \n",
    "    #str1 = page.text[:400] # print the first 400 characters\n",
    "    obj1 = page.json() #convert text to py obj\n",
    "    print(page.url) # print the url that was fetched\n",
    "    return obj1\n",
    "\n",
    "def extract_movie_titles(objct1):\n",
    "    movie_titles = []\n",
    "    for movi in objct1['Similar']['Results']:\n",
    "        movie_titles.append(movi['Name'])\n",
    "    return movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# some invocations that we use in the automated tests; uncomment these if you are getting errors and want better error messages\n",
    "# get_related_titles([\"Black Panther\", \"Captain Marvel\"])\n",
    "# get_related_titles([])\n",
    "import requests_with_caching\n",
    "\n",
    "def get_movies_from_tastedive(title1):\n",
    "    kval_pairs = {'q':title1, 'type':'movies', 'limit':'5'}\n",
    "    page = requests_with_caching.get(\"https://tastedive.com/api/similar\", params=kval_pairs)  \n",
    "    #str1 = page.text[:400] # print the first 400 characters\n",
    "    obj1 = page.json() #convert text to py obj\n",
    "    print(page.url) # print the url that was fetched\n",
    "    return obj1\n",
    "\n",
    "\n",
    "def extract_movie_titles(objct1):\n",
    "    movie_titles = []\n",
    "    for movi in objct1['Similar']['Results']:\n",
    "        movie_titles.append(movi['Name'])\n",
    "    return movie_titles\n",
    "\n",
    "def get_related_titles(list1):\n",
    "    related_titles = []\n",
    "    for mv1 in list1:\n",
    "        templst = extract_movie_titles(get_movies_from_tastedive(mv1))\n",
    "        for mv2 in templst:\n",
    "            if mv2 not in related_titles:\n",
    "                related_titles.append(mv2)\n",
    "    return related_titles\n",
    "\n",
    "get_related_titles([\"Black Panther\", \"Captain Marvel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# some invocations that we use in the automated tests; uncomment these if you are getting errors and want better error messages\n",
    "# get_sorted_recommendations([\"Bridesmaids\", \"Sherlock Holmes\"])\n",
    "import requests_with_caching\n",
    "import json\n",
    "\n",
    "def get_movies_from_tastedive(title1):\n",
    "    kval_pairs = {'q':title1, 'type':'movies', 'limit':'5'}\n",
    "    page = requests_with_caching.get(\"https://tastedive.com/api/similar\", params=kval_pairs)  \n",
    "    #str1 = page.text[:400] # print the first 400 characters\n",
    "    obj1 = page.json() #convert text to py obj\n",
    "    #print(page.url) # print the url that was fetched\n",
    "    return obj1\n",
    "\n",
    "\n",
    "def extract_movie_titles(objct1):\n",
    "    movie_titles = []\n",
    "    for movi in objct1['Similar']['Results']:\n",
    "        movie_titles.append(movi['Name'])\n",
    "    return movie_titles\n",
    "\n",
    "def get_related_titles(list1):\n",
    "    related_titles = []\n",
    "    for mv1 in list1:\n",
    "        templst = extract_movie_titles(get_movies_from_tastedive(mv1))\n",
    "        for mv2 in templst:\n",
    "            if mv2 not in related_titles:\n",
    "                related_titles.append(mv2)\n",
    "    return related_titles\n",
    "\n",
    "def get_movie_rating(mvobj):\n",
    "    for ratin in mvobj['Ratings']:\n",
    "        if ratin['Source'] == 'Rotten Tomatoes':\n",
    "            return int( ratin['Value'].strip('%') )\n",
    "    return 0             \n",
    "\n",
    "def get_movie_data(title):\n",
    "    d = {'t':title, 'r':'json'}\n",
    "    request = requests_with_caching.get('http://www.omdbapi.com/', params=d)\n",
    "    #print (request.json())\n",
    "    #return request.json()\n",
    "    return get_movie_rating(request.json())\n",
    "\n",
    "def get_sorted_recommendations(listmv):\n",
    "    relatedlst = get_related_titles(listmv)\n",
    "    lstrate = map(get_movie_data, relatedlst)\n",
    "    dict1 = dict( zip(relatedlst,lstrate) )\n",
    "    print(dict1)\n",
    "    list1sorted = sorted(dict1.items(), key=lambda x: (x[1],x[0]),reverse=True )\n",
    "    listnames = []\n",
    "    for tup in list1sorted:\n",
    "        listnames.append(tup[0])\n",
    "    print(listnames)\n",
    "    return listnames\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
